{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import seaborn as sns\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"BazaCut/\"\n",
    "FILIP_PATH = DATA_PATH + \"wordsFilip/\"\n",
    "SEB_PATH = DATA_PATH + \"wordsSebastian/\"\n",
    "MARCIN_PATH = DATA_PATH + \"wordsMarcin/\"\n",
    "PROF_PATH = DATA_PATH + \"wordsProfessor/\"\n",
    "\n",
    "FILIP_PATH_SENT = DATA_PATH + \"sentencesFilip/\"\n",
    "SEB_PATH_SENT  = DATA_PATH + \"sentencesSebastian/\"\n",
    "MARCIN_PATH_SENT  = DATA_PATH + \"sentencesMarcin/\"\n",
    "PROF_PATH_SENT  = DATA_PATH + \"sentencesProfessor/\"\n",
    "\n",
    "no_of_words = 30\n",
    "no_of_sentences = 45\n",
    "prefixes = [\"F\",\"S\",\"M\",\"L\"]\n",
    "Fs = 48000\n",
    "\n",
    "words_filip = [i for i in range(no_of_words)]\n",
    "words_seb = [i for i in range(no_of_words)]\n",
    "words_marcin = [i for i in range(no_of_words)]\n",
    "words_prof = [i for i in range(no_of_words)]\n",
    "\n",
    "sentences_filip = [i for i in range(no_of_sentences)]\n",
    "sentences_seb = [i for i in range(no_of_sentences)]\n",
    "sentences_marcin = [i for i in range(no_of_sentences)]\n",
    "sentences_prof = [i for i in range(no_of_sentences)]\n",
    "neutral = [\"N\"]*15\n",
    "happy = [\"H\"] *15\n",
    "anger = [\"A\"] *15\n",
    "L = neutral+happy+anger\n",
    "\n",
    "\n",
    "NOISE_PATH = \"BazaNoise/\"\n",
    "noise_file = NOISE_PATH + \"noise.wav\"\n",
    "y, sr = librosa.load(noise_file, sr=None)\n",
    "NOISE = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytywanie słów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, no_of_words+1):\n",
    "    file_name = \"word\"+str(i)+\"_F\"+\".wav\"\n",
    "    y, sr = librosa.load(FILIP_PATH+file_name, sr=None)\n",
    "    words_filip[i-1] = y\n",
    "\n",
    "for i in range(1, no_of_words+1):\n",
    "    file_name = \"word\"+str(i)+\"_S\"+\".wav\"\n",
    "    y, sr = librosa.load(SEB_PATH+file_name, sr=None)\n",
    "    words_seb[i-1] = y\n",
    "\n",
    "for i in range(1, no_of_words+1):\n",
    "    file_name = \"word\"+str(i)+\"_M\"+\".wav\"\n",
    "    y, sr = librosa.load(MARCIN_PATH+file_name, sr=None)\n",
    "    words_marcin[i-1] = y\n",
    "\n",
    "for i in range(1, no_of_words+1):\n",
    "    file_name = \"word\"+str(i)+\"_L\"+\".wav\"\n",
    "    y, sr = librosa.load(PROF_PATH+file_name, sr=None)\n",
    "    words_prof[i-1] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wczytywanie zdań"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, no_of_sentences+1):\n",
    "    file_name = \"sentence\"+str(i)+L[i-1]+\"_F\"+\".wav\"\n",
    "    y, sr = librosa.load(FILIP_PATH_SENT+file_name, sr=None)\n",
    "    sentences_filip[i-1] = y\n",
    "\n",
    "for i in range(1, no_of_sentences+1):\n",
    "    file_name = \"sentence\"+str(i)+L[i-1]+\"_S\"+\".wav\"\n",
    "    y, sr = librosa.load(SEB_PATH_SENT+file_name, sr=None)\n",
    "    sentences_seb[i-1] = y\n",
    "\n",
    "for i in range(1, no_of_sentences+1):\n",
    "    file_name = \"sentence\"+str(i)+L[i-1]+\"_M\"+\".wav\"\n",
    "    y, sr = librosa.load(MARCIN_PATH_SENT+file_name, sr=None)\n",
    "    sentences_marcin[i-1] = y\n",
    "\n",
    "for i in range(1, no_of_sentences+1):\n",
    "    file_name = \"sentence\"+str(i)+L[i-1]+\"_L\"+\".wav\"\n",
    "    y, sr = librosa.load(PROF_PATH_SENT+file_name, sr=None)\n",
    "    sentences_prof[i-1] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dodawanie nagranego hałasu do słów\n",
    "### x\\*mowa+y\\*hałas\n",
    "### x,y w (0,1) i x+y = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to output_audio.wav\n"
     ]
    }
   ],
   "source": [
    "curr_word = words_filip[2]\n",
    "length = len(curr_word)\n",
    "noise_to_add = NOISE[:length]\n",
    "\n",
    "added_noise = curr_word*0.5+noise_to_add*0.5\n",
    "output_file = 'output_audio.wav'\n",
    "sf.write(output_file, added_noise, sr)\n",
    "\n",
    "print(f\"Audio saved to {output_file}\")\n",
    "#Działa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_and_save_added_noise(data,noise,folder_path, which):\n",
    "    noise_proportions = np.arange(0.1,1,0.1)\n",
    "    no_of_words = len(data)\n",
    "    for noise_proportion in noise_proportions:\n",
    "        for i in range(no_of_words):\n",
    "            curr_word = data[i]\n",
    "            length = len(curr_word)\n",
    "            noise_to_add = noise[:length]\n",
    "            speech_power = 1 - noise_proportion\n",
    "            \n",
    "            added_noise = curr_word*speech_power+noise_to_add*noise_proportion\n",
    "            sufix = \"_\"+\"N\"+str(int(noise_proportion*100))\n",
    "            which_person = \"_\"+which\n",
    "            file_name = \"word\"+str(i)+which_person+sufix+\".wav\"\n",
    "            full_path = folder_path+file_name\n",
    "\n",
    "            sf.write(full_path, added_noise, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dodawanie szumu do słów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"BazaNoise/\"\n",
    "FILIP_PATH = DATA_PATH + \"wordsFilipNoise/\"\n",
    "SEB_PATH = DATA_PATH + \"wordsSebastianNoise/\"\n",
    "MARCIN_PATH = DATA_PATH + \"wordsMarcinNoise/\"\n",
    "PROF_PATH = DATA_PATH + \"wordsProfessorNoise/\"\n",
    "\n",
    "#Filip\n",
    "noise_proportions = np.arange(0.1,1,0.1)\n",
    "\n",
    "add_and_save_added_noise(words_filip, NOISE, FILIP_PATH,\"F\")        \n",
    "add_and_save_added_noise(words_seb, NOISE, SEB_PATH,\"S\")    \n",
    "add_and_save_added_noise(words_marcin, NOISE, MARCIN_PATH,\"M\")    \n",
    "add_and_save_added_noise(words_prof, NOISE, PROF_PATH,\"L\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dodawanie szumu do zdań"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_and_save_added_noise(data,noise,folder_path, which,labels):\n",
    "    noise_proportions = np.arange(0.1,1,0.1)\n",
    "    no_of_sentences = len(data)\n",
    "    for noise_proportion in noise_proportions:\n",
    "        for i in range(no_of_sentences):\n",
    "            curr_word = data[i]\n",
    "            length = len(curr_word)\n",
    "            noise_to_add = noise[:length]\n",
    "            speech_power = 1 - noise_proportion\n",
    "            \n",
    "            added_noise = curr_word*speech_power+noise_to_add*noise_proportion\n",
    "            sufix = \"_\"+\"N\"+str(int(noise_proportion*100))\n",
    "            which_person = \"_\"+which\n",
    "\n",
    "            file_name = \"sentence\"+str(i+1)+labels[i]+which_person+sufix+\".wav\"\n",
    "            full_path = folder_path+file_name\n",
    "\n",
    "            sf.write(full_path, added_noise, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00038791 -0.00017631 -0.00066841 ...  0.00053966  0.00057769\n",
      "  0.00061023]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"BazaNoise/\"\n",
    "FILIP_PATH = DATA_PATH + \"sentencesFilipNoise/\"\n",
    "SEB_PATH = DATA_PATH + \"sentencesSebastianNoise/\"\n",
    "MARCIN_PATH = DATA_PATH + \"sentencesMarcinNoise/\"\n",
    "PROF_PATH = DATA_PATH + \"sentencesProfessorNoise/\"\n",
    "\n",
    "\n",
    "add_and_save_added_noise(sentences_filip, NOISE,FILIP_PATH,\"F\",L)\n",
    "add_and_save_added_noise(sentences_seb, NOISE,SEB_PATH,\"S\",L)\n",
    "add_and_save_added_noise(sentences_marcin, NOISE,MARCIN_PATH,\"M\",L)\n",
    "add_and_save_added_noise(sentences_prof, NOISE,PROF_PATH,\"L\",L)\n",
    "\n",
    "print(sentences_prof[30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
